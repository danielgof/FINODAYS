{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import nltk\r\n",
    "import string\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.stem import SnowballStemmer\r\n",
    "nltk.download('punkt')\r\n",
    "nltk.download('stopwords')\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "from sklearn.metrics import plot_precision_recall_curve\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv(\"testdata.manual.2009.06.14.csv\", sep=\",\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>Mon May 11 03:17:40 UTC 2009</th>\n",
       "      <th>kindle2</th>\n",
       "      <th>tpryan</th>\n",
       "      <th>@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   4  3  Mon May 11 03:17:40 UTC 2009  kindle2        tpryan  \\\n",
       "0  4  4  Mon May 11 03:18:03 UTC 2009  kindle2        vcu451   \n",
       "1  4  5  Mon May 11 03:18:54 UTC 2009  kindle2        chadfu   \n",
       "2  4  6  Mon May 11 03:19:04 UTC 2009  kindle2         SIX15   \n",
       "3  4  7  Mon May 11 03:21:41 UTC 2009  kindle2      yamarama   \n",
       "4  4  8  Mon May 11 03:22:00 UTC 2009  kindle2  GeorgeVHulme   \n",
       "\n",
       "  @stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.  \n",
       "0  Reading my kindle2...  Love it... Lee childs i...                                                               \n",
       "1  Ok, first assesment of the #kindle2 ...it fuck...                                                               \n",
       "2  @kenburbary You'll love your Kindle2. I've had...                                                               \n",
       "3  @mikefish  Fair enough. But i have the Kindle2...                                                               \n",
       "4  @richardebaker no. it is too big. I'm quite ha...                                                               "
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.columns=[0, 1, 2, 3, 4, 5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1                             2        3             4  \\\n",
       "0  4  4  Mon May 11 03:18:03 UTC 2009  kindle2        vcu451   \n",
       "1  4  5  Mon May 11 03:18:54 UTC 2009  kindle2        chadfu   \n",
       "2  4  6  Mon May 11 03:19:04 UTC 2009  kindle2         SIX15   \n",
       "3  4  7  Mon May 11 03:21:41 UTC 2009  kindle2      yamarama   \n",
       "4  4  8  Mon May 11 03:22:00 UTC 2009  kindle2  GeorgeVHulme   \n",
       "\n",
       "                                                   5  \n",
       "0  Reading my kindle2...  Love it... Lee childs i...  \n",
       "1  Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "2  @kenburbary You'll love your Kindle2. I've had...  \n",
       "3  @mikefish  Fair enough. But i have the Kindle2...  \n",
       "4  @richardebaker no. it is too big. I'm quite ha...  "
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(497, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df.describe"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      0      1                             2        3                4  \\\n",
       "0    4      4  Mon May 11 03:18:03 UTC 2009  kindle2           vcu451   \n",
       "1    4      5  Mon May 11 03:18:54 UTC 2009  kindle2           chadfu   \n",
       "2    4      6  Mon May 11 03:19:04 UTC 2009  kindle2            SIX15   \n",
       "3    4      7  Mon May 11 03:21:41 UTC 2009  kindle2         yamarama   \n",
       "4    4      8  Mon May 11 03:22:00 UTC 2009  kindle2     GeorgeVHulme   \n",
       "..  ..    ...                           ...      ...              ...   \n",
       "492  2  14072  Sun Jun 14 04:31:43 UTC 2009    latex          proggit   \n",
       "493  0  14073  Sun Jun 14 04:32:17 UTC 2009    latex           sam33r   \n",
       "494  4  14074  Sun Jun 14 04:36:34 UTC 2009    latex  iamtheonlyjosie   \n",
       "495  0  14075  Sun Jun 14 21:36:07 UTC 2009     iran        plutopup7   \n",
       "496  0  14076  Sun Jun 14 21:36:17 UTC 2009     iran     captain_pete   \n",
       "\n",
       "                                                     5  \n",
       "0    Reading my kindle2...  Love it... Lee childs i...  \n",
       "1    Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "2    @kenburbary You'll love your Kindle2. I've had...  \n",
       "3    @mikefish  Fair enough. But i have the Kindle2...  \n",
       "4    @richardebaker no. it is too big. I'm quite ha...  \n",
       "..                                                 ...  \n",
       "492  Ask Programming: LaTeX or InDesign?: submitted...  \n",
       "493  On that note, I hate Word. I hate Pages. I hat...  \n",
       "494  Ahhh... back in a *real* text editing environm...  \n",
       "495  Trouble in Iran, I see. Hmm. Iran. Iran so far...  \n",
       "496  Reading the tweets coming out of Iran... The w...  \n",
       "\n",
       "[497 rows x 6 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df_new = df.drop([1, 2, 3, 4], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df_new"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2</td>\n",
       "      <td>Ask Programming: LaTeX or InDesign?: submitted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0</td>\n",
       "      <td>On that note, I hate Word. I hate Pages. I hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>4</td>\n",
       "      <td>Ahhh... back in a *real* text editing environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>Trouble in Iran, I see. Hmm. Iran. Iran so far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>Reading the tweets coming out of Iran... The w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                                  5\n",
       "0    4  Reading my kindle2...  Love it... Lee childs i...\n",
       "1    4  Ok, first assesment of the #kindle2 ...it fuck...\n",
       "2    4  @kenburbary You'll love your Kindle2. I've had...\n",
       "3    4  @mikefish  Fair enough. But i have the Kindle2...\n",
       "4    4  @richardebaker no. it is too big. I'm quite ha...\n",
       "..  ..                                                ...\n",
       "492  2  Ask Programming: LaTeX or InDesign?: submitted...\n",
       "493  0  On that note, I hate Word. I hate Pages. I hat...\n",
       "494  4  Ahhh... back in a *real* text editing environm...\n",
       "495  0  Trouble in Iran, I see. Hmm. Iran. Iran so far...\n",
       "496  0  Reading the tweets coming out of Iran... The w...\n",
       "\n",
       "[497 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df[0].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4    181\n",
       "0    177\n",
       "2    139\n",
       "Name: 0, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "for c in df[df[0] == 4][5].head(5):\r\n",
    "    print(c)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading my kindle2...  Love it... Lee childs is good read.\n",
      "Ok, first assesment of the #kindle2 ...it fucking rocks!!!\n",
      "@kenburbary You'll love your Kindle2. I've had mine for a few months and never looked back. The new big one is huge! No need for remorse! :)\n",
      "@mikefish  Fair enough. But i have the Kindle2 and I think it's perfect  :)\n",
      "@richardebaker no. it is too big. I'm quite happy with the Kindle2.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for c in df[df[0] == 2][5].head(5):\r\n",
    "    print(c)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Check this video out -- President Obama at the White House Correspondents' Dinner http://bit.ly/IMXUM\n",
      "need suggestions for a good IR filter for my canon 40D ... got some? pls DM\n",
      "@surfit: I just checked my google for my business- blip shows up as the second entry! Huh. Is that a good or ba... ? http://blip.fm/~6emhv\n",
      "is in San Francisco at Bay to Breakers.\n",
      "just landed at San Francisco\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for c in df[df[0] == 0][5].head(5):\r\n",
    "    print(c)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fuck this economy. I hate aig and their non loan given asses.\n",
      "@Karoli I firmly believe that Obama/Pelosi have ZERO desire to be civil.  It's a charade and a slogan, but they want to destroy conservatism\n",
      "dear nike, stop with the flywire. that shit is a waste of science. and ugly. love, @vincentx24x\n",
      "I was talking to this guy last night and he was telling me that he is a die hard Spurs fan.  He also told me that he hates LeBron James.\n",
      "@ludajuice Lebron is a Beast, but I'm still cheering 4 the A..til the end.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_df, test_df = train_test_split(df, test_size=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "sentence_example = df.iloc[1][5]\r\n",
    "tokens = word_tokenize(sentence_example, language=\"english\")\r\n",
    "tokens_without_punctuation = [i for i in tokens if i not in string.punctuation]\r\n",
    "russian_stop_words = stopwords.words(\"english\")\r\n",
    "tokens_without_stop_words_and_punctuation = [i for i in tokens_without_punctuation if i not in russian_stop_words]\r\n",
    "snowball = SnowballStemmer(language=\"english\")\r\n",
    "stemmed_tokens = [snowball.stem(i) for i in tokens_without_stop_words_and_punctuation]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "print(f\"Исходный текст: {sentence_example}\")\r\n",
    "print(\"-----------------\")\r\n",
    "print(f\"Токены: {tokens}\")\r\n",
    "print(\"-----------------\")\r\n",
    "print(f\"Токены без пунктуации: {tokens_without_punctuation}\")\r\n",
    "print(\"-----------------\")\r\n",
    "print(f\"Токены без пунктуации и стоп слов: {tokens_without_stop_words_and_punctuation}\")\r\n",
    "print(\"-----------------\")\r\n",
    "print(f\"Токены после стемминга: {stemmed_tokens}\")\r\n",
    "print(\"-----------------\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Исходный текст: Ok, first assesment of the #kindle2 ...it fucking rocks!!!\n",
      "-----------------\n",
      "Токены: ['Ok', ',', 'first', 'assesment', 'of', 'the', '#', 'kindle2', '...', 'it', 'fucking', 'rocks', '!', '!', '!']\n",
      "-----------------\n",
      "Токены без пунктуации: ['Ok', 'first', 'assesment', 'of', 'the', 'kindle2', '...', 'it', 'fucking', 'rocks']\n",
      "-----------------\n",
      "Токены без пунктуации и стоп слов: ['Ok', 'first', 'assesment', 'kindle2', '...', 'fucking', 'rocks']\n",
      "-----------------\n",
      "Токены после стемминга: ['ok', 'first', 'asses', 'kindle2', '...', 'fuck', 'rock']\n",
      "-----------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "snowball = SnowballStemmer(language=\"english\")\r\n",
    "english_stop_words = stopwords.words(\"english\")\r\n",
    "\r\n",
    "def tokenize_sentence(sentence: str, remove_stop_words: bool = True):\r\n",
    "    tokens = word_tokenize(sentence, language=\"english\")\r\n",
    "    tokens = [i for i in tokens if i not in string.punctuation]\r\n",
    "    if remove_stop_words:\r\n",
    "        tokens = [i for i in tokens if i not in english_stop_words]\r\n",
    "    tokens = [snowball.stem(i) for i in tokens]\r\n",
    "    return tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "tokenize_sentence(sentence_example)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['ok', 'first', 'asses', 'kindle2', '...', 'fuck', 'rock']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "features = vectorizer.fit_transform(train_df[5])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "model = LogisticRegression(random_state=0)\r\n",
    "model.fit(features, train_df[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "model.predict(features[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "train_df[5].iloc[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'NOOOOOOO my DVR just died and I was only half way through the EA presser. Hate you Time Warner'"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "model_pipeline = Pipeline([\r\n",
    "    (\"vectorizer\", TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))),\r\n",
    "    (\"model\", LogisticRegression(random_state=0))\r\n",
    "]\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "model_pipeline.fit(train_df[5], train_df[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(tokenizer=<function <lambda> at 0x000001EA8899DF70>)),\n",
       "                ('model', LogisticRegression(random_state=0))])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "model_pipeline.predict([\"Hello, are you okay?\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "model_pipeline.predict([\"Hello\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "model_pipeline.predict([\"fuck you\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "model_pipeline.predict([\"hello, I really don't like this\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "75384fd0ca3c2952361a90566c13d130cab84e43a6c89416ac57c7dceece1b2d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}